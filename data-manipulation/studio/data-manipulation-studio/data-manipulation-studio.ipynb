{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1894ccac",
   "metadata": {},
   "source": [
    "# Data Manipulation Studio\n",
    "\n",
    "For this studio, we will revisit the data set from our last studio. If you recall, California farmers were looking for advice on growing pumpkins. We will use the same [pumpkins dataset](https://www.kaggle.com/usda/a-year-of-pumpkin-prices) as provided by the U.S. Department of Agriculture. You may have to clean data in the process of data manipulation, so feel free to pull up your notebook from the last class's studio.\n",
    "\n",
    "We will now be focusing our attention on a different region in the United States, the Northeast. When you open up the `dataset` folder, you will have 13 CSVs, including the San Francisco and Los Angeles data from the last lesson. The 13 CSVs are each a different terminal market in the United States.\n",
    "\n",
    "A **terminal market** is a central site, often in a metropolitan area, that serves as an assembly and trading place for commodities. Terminal markets for agricultural commodities are usually at or near major transportation hubs. [Definition Source](https://en.wikipedia.org/wiki/Terminal_market#:~:text=A%20terminal%20market%20is%20a,or%20near%20major%20transportation%20hubs)\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Import the CSVs for each of the following cities: Baltimore, Boston, New York, and Philadelphia. Set up a dataframe for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c9a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and CSVs. Make some dataframes!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "baltimore = pd.read_csv(r\"C:\\Users\\madhu\\Launchcode\\DataAnalysisProjects\\data-analysis-projects\\data-manipulation\\studio\\data-manipulation-studio\\dataset\\baltimore_9-24-2016_9-30-2017.csv\")\n",
    "boston= pd.read_csv(r\"C:\\Users\\madhu\\Launchcode\\DataAnalysisProjects\\data-analysis-projects\\data-manipulation\\studio\\data-manipulation-studio\\dataset\\boston_9-24-2016_9-30-2017.csv\")\n",
    "newyork = pd.read_csv(r\"C:\\Users\\madhu\\Launchcode\\DataAnalysisProjects\\data-analysis-projects\\data-manipulation\\studio\\data-manipulation-studio\\dataset\\new-york_9-24-2016_9-30-2017.csv\")\n",
    "philly = pd.read_csv(r\"C:\\Users\\madhu\\Launchcode\\DataAnalysisProjects\\data-analysis-projects\\data-manipulation\\studio\\data-manipulation-studio\\dataset\\philadelphia_9-24-2016_9-30-2017.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfda42f",
   "metadata": {},
   "source": [
    "## Clean Your Data\n",
    "\n",
    "In the last lesson, we cleaned the data related to San Francisco. Pull up your notebook from the last lesson and use it as a reference to clean up these new dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98abc290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 1%\n",
      "Sub Variety - 84%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 3%\n",
      "Origin District - 100%\n",
      "Item Size - 16%\n",
      "Color - 80%\n",
      "Environment - 100%\n",
      "Unit of Sale - 84%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "# Clean your data here!\n",
    "for col in baltimore.columns:\n",
    "    pct_missing = np.mean(baltimore[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0666c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baltimore= baltimore.drop([\"Grade\"], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab904797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 84%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 87%\n",
      "Item Size - 7%\n",
      "Color - 81%\n",
      "Environment - 100%\n",
      "Unit of Sale - 78%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "for col in newyork.columns:\n",
    "    pct_missing = np.mean(newyork[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed55458f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 92%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 81%\n",
      "Item Size - 1%\n",
      "Color - 14%\n",
      "Environment - 100%\n",
      "Unit of Sale - 87%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "for col in boston.columns:\n",
    "    pct_missing = np.mean(boston[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1731ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 79%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 100%\n",
      "Item Size - 21%\n",
      "Color - 100%\n",
      "Environment - 100%\n",
      "Unit of Sale - 81%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "for col in philly.columns:\n",
    "    pct_missing = np.mean(philly[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b01b9",
   "metadata": {},
   "source": [
    "## Combine Your Data\n",
    "\n",
    "Now that you have four clean sets of data, combine all four into one dataframe that represents the entire Northeast region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da059f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the four dataframes into one!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8590082f",
   "metadata": {},
   "source": [
    "## Answer Some Questions\n",
    "\n",
    "Use `groupby()` and `agg()` to answer the following two questions:\n",
    "\n",
    "1. What is the mean low and high prices for each type of **unit of sale** in the Northeast region? \n",
    "2. For each region, what is the average number of pumpkins per variety that came into terminal markets for the year? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c839639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here to find the mean low and high prices in the Northeast region for each type of unit of sale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b4b23352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here to find the average number of pumpkins coming into terminal markets of each variety.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5cff4",
   "metadata": {},
   "source": [
    "## Bonus Mission\n",
    "\n",
    "Try answering the same questions for the Midwest (Chicago, Detroit, and St. Louis) or the Southeast (Atlanta, Columbia, and Miami) regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d22b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the bonus mission if you have time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbc152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
